{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import seaborn as sns\n",
    "from ModelTree import ModelTree\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"stocks.xlsx\", sheet_name=\"4th period\")\n",
    "names = df.iloc[0, :]\n",
    "df = pd.read_excel(\"stocks.xlsx\", sheet_name=\"4th period\", names=names)\n",
    "df.drop(axis=0, labels=[0], inplace=True)\n",
    "\n",
    "df2 = pd.read_excel(\"stocks.xlsx\", sheet_name=\"3rd period\")\n",
    "names = df2.iloc[0, :]\n",
    "df2 = pd.read_excel(\"stocks.xlsx\", sheet_name=\"3rd period\", names=names)\n",
    "df2.drop(axis=0, labels=[0], inplace=True)\n",
    "\n",
    "df3 = pd.read_excel(\"stocks.xlsx\", sheet_name=\"2nd period\")\n",
    "names = df3.iloc[0, :]\n",
    "df3 = pd.read_excel(\"stocks.xlsx\", sheet_name=\"2nd period\", names=names)\n",
    "df3.drop(axis=0, labels=[0], inplace=True)\n",
    "\n",
    "df4 = pd.read_excel(\"stocks.xlsx\", sheet_name=\"1st period\")\n",
    "names = df4.iloc[0, :]\n",
    "df4 = pd.read_excel(\"stocks.xlsx\", sheet_name=\"1st period\", names=names)\n",
    "df4.drop(axis=0, labels=[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the dataframes for all periods in the dataset and drop ID column which will be later reset as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df2, df3, df4])\n",
    "df.drop(axis=1, labels=[\"ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns which represent the target variables with absolute values, which leaves us working with the ones containing normalized stocks' performance indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=1, columns=df.columns[[6,7,8,9,10,11]], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.columns = ['LargeB/P', 'LargeROE', 'LargeS/P', 'LargeReturnRateInTheLastQuarter', \"LargeMarketValue\", 'SmallSystematicRisk', 'AnnualReturn', 'ExcessReturn', 'SystematicRisk', 'TotalRisk', 'AbsWinRate', 'RelWinRate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns data types and see if any changes are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "\n",
    "# all columns have \"object\" data type, so we need to change them to float\n",
    "for col in df.columns: \n",
    "    df[col] = pd.to_numeric(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LargeB/P</th>\n",
       "      <th>LargeROE</th>\n",
       "      <th>LargeS/P</th>\n",
       "      <th>LargeReturnRateInTheLastQuarter</th>\n",
       "      <th>LargeMarketValue</th>\n",
       "      <th>SmallSystematicRisk</th>\n",
       "      <th>AnnualReturn</th>\n",
       "      <th>ExcessReturn</th>\n",
       "      <th>SystematicRisk</th>\n",
       "      <th>TotalRisk</th>\n",
       "      <th>AbsWinRate</th>\n",
       "      <th>RelWinRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.542936</td>\n",
       "      <td>0.568207</td>\n",
       "      <td>0.427889</td>\n",
       "      <td>0.430264</td>\n",
       "      <td>0.537143</td>\n",
       "      <td>0.541964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.198110</td>\n",
       "      <td>0.198110</td>\n",
       "      <td>0.198110</td>\n",
       "      <td>0.198110</td>\n",
       "      <td>0.198110</td>\n",
       "      <td>0.198110</td>\n",
       "      <td>0.145835</td>\n",
       "      <td>0.135865</td>\n",
       "      <td>0.140281</td>\n",
       "      <td>0.146439</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>0.142311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450578</td>\n",
       "      <td>0.486764</td>\n",
       "      <td>0.325702</td>\n",
       "      <td>0.319333</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.555995</td>\n",
       "      <td>0.580902</td>\n",
       "      <td>0.411967</td>\n",
       "      <td>0.399398</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.655166</td>\n",
       "      <td>0.671781</td>\n",
       "      <td>0.505836</td>\n",
       "      <td>0.516704</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LargeB/P    LargeROE    LargeS/P  LargeReturnRateInTheLastQuarter  \\\n",
       "count  252.000000  252.000000  252.000000                       252.000000   \n",
       "mean     0.166619    0.166619    0.166619                         0.166619   \n",
       "std      0.198110    0.198110    0.198110                         0.198110   \n",
       "min      0.000000    0.000000    0.000000                         0.000000   \n",
       "25%      0.000000    0.000000    0.000000                         0.000000   \n",
       "50%      0.167000    0.167000    0.167000                         0.167000   \n",
       "75%      0.333000    0.333000    0.333000                         0.333000   \n",
       "max      1.000000    1.000000    1.000000                         1.000000   \n",
       "\n",
       "       LargeMarketValue  SmallSystematicRisk  AnnualReturn  ExcessReturn  \\\n",
       "count        252.000000           252.000000    252.000000    252.000000   \n",
       "mean           0.166619             0.166619      0.542936      0.568207   \n",
       "std            0.198110             0.198110      0.145835      0.135865   \n",
       "min            0.000000             0.000000      0.200000      0.200000   \n",
       "25%            0.000000             0.000000      0.450578      0.486764   \n",
       "50%            0.167000             0.167000      0.555995      0.580902   \n",
       "75%            0.333000             0.333000      0.655166      0.671781   \n",
       "max            1.000000             1.000000      0.800000      0.800000   \n",
       "\n",
       "       SystematicRisk   TotalRisk  AbsWinRate  RelWinRate  \n",
       "count      252.000000  252.000000  252.000000  252.000000  \n",
       "mean         0.427889    0.430264    0.537143    0.541964  \n",
       "std          0.140281    0.146439    0.140391    0.142311  \n",
       "min          0.200000    0.200000    0.200000    0.200000  \n",
       "25%          0.325702    0.319333    0.457143    0.425000  \n",
       "50%          0.411967    0.399398    0.560000    0.533333  \n",
       "75%          0.505836    0.516704    0.628571    0.650000  \n",
       "max          0.800000    0.800000    0.800000    0.800000  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df.pop('AnnualReturn'))\n",
    "X = df.iloc[:, [0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.03858032736233476\n",
      "Mean Absolute Error: 0.1585568539852644\n"
     ]
    }
   ],
   "source": [
    "ScikitDecisionTreeModel=DecisionTreeRegressor(max_depth=50, min_samples_split=2)\n",
    "ScikitDecisionTreeModel.fit(x_train, y_train)\n",
    "\n",
    "y_pred=ScikitDecisionTreeModel.predict(x_test)\n",
    "\n",
    "print(\"Mean Squared Error: \" + str(mean_squared_error(y_test, y_pred)))\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LargeB/P',\n",
       " 'LargeROE',\n",
       " 'LargeS/P',\n",
       " 'LargeReturnRateInTheLastQuarter',\n",
       " 'LargeMarketValue',\n",
       " 'SmallSystematicRisk']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_importance=ScikitDecisionTreeModel.feature_importances_\n",
    "indexes=[]\n",
    "for i in range(len(features_importance)):\n",
    "    # select only the features that have any relevance\n",
    "    if features_importance[i]!=0:\n",
    "        indexes.append(i)\n",
    "relevant_features=[]\n",
    "for i in range(len(X.columns)):\n",
    "    if i in indexes:\n",
    "        relevant_features.append(df.columns[i])\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have so few features (6), all got selected and filtered as \"important\" by the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation on scikit's tree implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.02868441582928566\n",
      "Mean Absolute Error: 0.13854598079457142\n"
     ]
    }
   ],
   "source": [
    "ScikitDecisionTreeModel=DecisionTreeRegressor(max_depth=50, min_samples_split=2)\n",
    "scores_mse = cross_val_score(ScikitDecisionTreeModel, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "scores_mae = cross_val_score(ScikitDecisionTreeModel, X, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "\n",
    "print(\"Mean Squared Error: \" + str(sum(scores_mse)*(-1)/len(scores_mse)))\n",
    "print(\"Mean Absolute Error: \" + str(sum(scores_mae)*(-1)/len(scores_mae)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Tree Regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecisionTreeRegressor():\n",
    "    \"\"\"\n",
    "    Class to build a regression decision tree\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        Y: list,\n",
    "        X: pd.DataFrame,\n",
    "        min_samples_split=None,\n",
    "        max_depth=None,\n",
    "        depth=None,\n",
    "        node_type=None,\n",
    "        rule=None\n",
    "    ):\n",
    "        # save the data to the node \n",
    "        self.Y = Y \n",
    "        self.X = X\n",
    "\n",
    "        # save the hyper parameters, define default values\n",
    "        self.min_samples_split = min_samples_split if min_samples_split else 2\n",
    "        self.max_depth = max_depth if max_depth else 10\n",
    "\n",
    "        # default current depth of node \n",
    "        self.depth = depth if depth else 0\n",
    "\n",
    "        # extract all the features\n",
    "        self.features = list(self.X.columns)\n",
    "\n",
    "        # type of node \n",
    "        self.node_type = node_type if node_type else 'root'\n",
    "\n",
    "        # rule for spliting \n",
    "        self.rule = rule if rule else \"\"\n",
    "\n",
    "        # get the mean of Y \n",
    "        self.ymean = np.mean(Y)\n",
    "\n",
    "        # get the residuals \n",
    "        self.residuals = self.Y - self.ymean\n",
    "\n",
    "        # calculate the mse of the node \n",
    "        self.mse = self.get_mse(Y, self.ymean)\n",
    "\n",
    "        # save the number of observations in the node \n",
    "        self.n = len(Y)\n",
    "\n",
    "        # initiate the left and right nodes as empty nodes\n",
    "        self.left = None \n",
    "        self.right = None \n",
    "\n",
    "        # default values for splits\n",
    "        self.best_feature = None \n",
    "        self.best_value = None \n",
    "\n",
    "    @staticmethod\n",
    "    def get_mse(ytrue, yhat) -> float:\n",
    "        \"\"\"\n",
    "        method to calculate the mean squared error \n",
    "        \"\"\"\n",
    "        # get the total number of samples\n",
    "        n = len(ytrue)\n",
    "\n",
    "        # get the residuals \n",
    "        r = ytrue - yhat \n",
    "\n",
    "        # square the residuals \n",
    "        r = r ** 2\n",
    "\n",
    "        # sum the squared residuals\n",
    "        r = np.sum(r)\n",
    "\n",
    "        # return the average \n",
    "        return r / n\n",
    "\n",
    "    @staticmethod\n",
    "    def ma(x: np.array, window: int) -> np.array:\n",
    "        \"\"\"\n",
    "        calculate the moving average of the given list. \n",
    "        \"\"\"\n",
    "        return np.convolve(x, np.ones(window), 'valid') / window\n",
    "\n",
    "    def best_split(self) -> tuple:\n",
    "        \"\"\"\n",
    "        given the X features and Y targets calculates the best split \n",
    "        for a decision tree\n",
    "        \"\"\"\n",
    "        # create a dataset for spliting\n",
    "        df = self.X.copy()\n",
    "        df['Y'] = self.Y\n",
    "\n",
    "        # get the GINI impurity for the base input \n",
    "        mse_base = self.mse\n",
    "\n",
    "        # find which split yields the best GINI gain \n",
    "        #max_gain = 0\n",
    "\n",
    "        # default best feature and split\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "\n",
    "        for feature in self.features:\n",
    "            # drop missing values\n",
    "            Xdf = df.dropna().sort_values(feature)\n",
    "\n",
    "            # sort the values and get the rolling average\n",
    "            xmeans = self.ma(Xdf[feature].unique(), 2)\n",
    "\n",
    "            for value in xmeans:\n",
    "                # get the left and right ys \n",
    "                left_y = Xdf[Xdf[feature]<value]['Y'].values\n",
    "                right_y = Xdf[Xdf[feature]>=value]['Y'].values\n",
    "\n",
    "                # get the means \n",
    "                left_mean = np.mean(left_y)\n",
    "                right_mean = np.mean(right_y)\n",
    "\n",
    "                # get the left and right residuals \n",
    "                res_left = left_y - left_mean \n",
    "                res_right = right_y - right_mean\n",
    "\n",
    "                # concatenate the residuals \n",
    "                r = np.concatenate((res_left, res_right), axis=None)\n",
    "\n",
    "                # calculate the mse \n",
    "                n = len(r)\n",
    "                r = r ** 2\n",
    "                r = np.sum(r)\n",
    "                mse_split = r / n\n",
    "\n",
    "                # check if this is the best split so far \n",
    "                if mse_split < mse_base:\n",
    "                    best_feature = feature\n",
    "                    best_value = value \n",
    "\n",
    "                    # get the best gain to the current one \n",
    "                    mse_base = mse_split\n",
    "\n",
    "        return (best_feature, best_value)\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        recursive method to create the decision tree\n",
    "        \"\"\"\n",
    "        # make a df from the data \n",
    "        df = self.X.copy()\n",
    "        df['Y'] = self.Y\n",
    "\n",
    "        # if there is GINI to be gained, we split further \n",
    "        if (self.depth < self.max_depth) and (self.n >= self.min_samples_split):\n",
    "\n",
    "            # get the best split \n",
    "            best_feature, best_value = self.best_split()\n",
    "\n",
    "            if best_feature is not None:\n",
    "                # save the best split to the current node \n",
    "                self.best_feature = best_feature\n",
    "                self.best_value = best_value\n",
    "\n",
    "                # gett the left and right nodes\n",
    "                left_df, right_df = df[df[best_feature]<=best_value].copy(), df[df[best_feature]>best_value].copy()\n",
    "\n",
    "                # create the left and right nodes\n",
    "                left = CustomDecisionTreeRegressor(\n",
    "                    left_df['Y'].values.tolist(), \n",
    "                    left_df[self.features], \n",
    "                    depth=self.depth + 1, \n",
    "                    max_depth=self.max_depth, \n",
    "                    min_samples_split=self.min_samples_split, \n",
    "                    node_type='left_node',\n",
    "                    rule=f\"{best_feature} <= {round(best_value, 3)}\"\n",
    "                    )\n",
    "\n",
    "                self.left = left \n",
    "                self.left.fit()\n",
    "\n",
    "                right = CustomDecisionTreeRegressor(\n",
    "                    right_df['Y'].values.tolist(), \n",
    "                    right_df[self.features], \n",
    "                    depth=self.depth + 1, \n",
    "                    max_depth=self.max_depth, \n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    node_type='right_node',\n",
    "                    rule=f\"{best_feature} > {round(best_value, 3)}\"\n",
    "                    )\n",
    "\n",
    "                self.right = right\n",
    "                self.right.fit()\n",
    "\n",
    "    def print_info(self, width=4):\n",
    "        \"\"\"\n",
    "        print information about one node\n",
    "        \"\"\"\n",
    "        # define the number of spaces \n",
    "        const = int(self.depth * width ** 1.5)\n",
    "        spaces = \"-\" * const\n",
    "        \n",
    "        if self.node_type == 'root':\n",
    "            print(\"Root\")\n",
    "        else:\n",
    "            print(f\"|{spaces} Split rule: {self.rule}\")\n",
    "        print(f\"{' ' * const}   | MSE of the node: {round(self.mse, 2)}\")\n",
    "        print(f\"{' ' * const}   | Count of observations in node: {self.n}\")\n",
    "        print(f\"{' ' * const}   | Prediction of node: {round(self.ymean, 3)}\")   \n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"\n",
    "        print the entire tree\n",
    "        \"\"\"\n",
    "        self.print_info() \n",
    "        \n",
    "        if self.left is not None: \n",
    "            self.left.print_tree()\n",
    "        \n",
    "        if self.right is not None:\n",
    "            self.right.print_tree()\n",
    "    def predict(self, dataframe):\n",
    "        \"\"\"\n",
    "        make predictions on a dataframe\n",
    "        \"\"\"\n",
    "        predictions=[]\n",
    "        for index, row in dataframe.iterrows():\n",
    "            node=root\n",
    "            while(node.left is not None and node.right is not None):\n",
    "\n",
    "                # get the rules for that node\n",
    "                left_rule=node.left.rule.split(\" \")\n",
    "                right_rule=node.right.rule.split(\" \")\n",
    "            \n",
    "                # continue on the left node\n",
    "                if (left_rule[1]==\"<=\"):\n",
    "                    if (row[left_rule[0]]<=float(left_rule[2])):\n",
    "                        node=node.left\n",
    "                elif (left_rule[1]==\"<\"):\n",
    "                    if (row[left_rule[0]]<float(left_rule[2])):\n",
    "                        node=node.left\n",
    "                elif (left_rule[1]==\">\"):\n",
    "                    if (row[left_rule[0]]>float(left_rule[2])):\n",
    "                        node=node.left\n",
    "                else:\n",
    "                    if (row[left_rule[0]]>=float(left_rule[2])):\n",
    "                        node=node.left\n",
    "\n",
    "                # contnue on the right node       \n",
    "                if (right_rule[1]==\"<=\"):\n",
    "                    if (row[right_rule[0]]<=float(right_rule[2])):\n",
    "                        node=node.right\n",
    "                elif (right_rule[1]==\"<\"):\n",
    "                    if (row[right_rule[0]]<float(right_rule[2])):\n",
    "                        node=node.right\n",
    "                elif (right_rule[1]==\">\"):\n",
    "                    if (row[right_rule[0]]>float(right_rule[2])):\n",
    "                        node=node.right\n",
    "                else:\n",
    "                    if (row[right_rule[0]]>=float(right_rule[2])):\n",
    "                        node=node.right\n",
    "\n",
    "                if (node.left is None and node.right is None):\n",
    "                    predictions.append(node.ymean)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout with CustomTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into 80/20 (training/test)\n",
    "threshold=int(0.8*X.shape[0])\n",
    "\n",
    "X_train = X[:threshold]\n",
    "Y_train = y[:threshold]\n",
    "X_test = X[threshold:]\n",
    "Y_test = y[threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tree\n",
    "root = CustomDecisionTreeRegressor(Y_train, X_train, max_depth=50, min_samples_split=2)\n",
    "# fit the tree\n",
    "root.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=root.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.024872547067057868\n",
      "Mean Absolute Error: 0.13359660508763005\n"
     ]
    }
   ],
   "source": [
    "# model evaluation using Root Mean Squared Error and Mean Absolute Error\n",
    "print(\"Mean Squared Error: \" + str(mean_squared_error(Y_test, predictions)))\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(Y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation with CustomTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 0.02643021057180304\n",
      "Average MAE: 0.13244258702713638\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "#define lists to store te results for each fold\n",
    "maes=[]\n",
    "mses=[]\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "        \n",
    "    # define the tree\n",
    "    root = CustomDecisionTreeRegressor(y_train, X_train, max_depth=50, min_samples_split=2)\n",
    "    # fit the tree\n",
    "    root.fit()\n",
    "    mse=mean_squared_error(y_test, root.predict(X_test))\n",
    "    mses.append(mse)\n",
    "    mae=mean_absolute_error(y_test, root.predict(X_test))\n",
    "    maes.append(mae)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"Average MSE: \" + str(np.mean(mses)))\n",
    "print(\"Average MAE: \" + str(np.mean(maes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout with ModelTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regr:\n",
    "\n",
    "    def __init__(self):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        self.model = LinearRegression()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def loss(self, X, y, y_pred):\n",
    "        return mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into 80/20 (training/test)\n",
    "threshold=int(0.8*X.shape[0])\n",
    "\n",
    "X_train = np.array(X[:threshold])\n",
    "Y_train = np.array(y[:threshold])\n",
    "X_test = np.array(X[threshold:])\n",
    "Y_test = np.array(y[threshold:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tree\n",
    "model = linear_regr()\n",
    "model_tree = ModelTree(model, max_depth=50, min_samples_leaf=2)\n",
    "model_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.024872547067057774\n",
      "Mean Absolute Error: 0.1335966050876297\n"
     ]
    }
   ],
   "source": [
    "# model evaluation using Root Mean Squared Error and Mean Absolute Error\n",
    "print(\"Mean Squared Error: \" + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation with ModelTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 0.026429292812349865\n",
      "Average MAE: 0.13243855189428613\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "#define lists to store te results for each fold\n",
    "maes=[]\n",
    "mses=[]\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train = np.array(X.iloc[train_index])\n",
    "    X_test = np.array(X.iloc[test_index])\n",
    "    Y_train = np.array(y[train_index])\n",
    "    Y_test = np.array(y[test_index])\n",
    "        \n",
    "    model = linear_regr()\n",
    "    model_tree = ModelTree(model, max_depth=50, min_samples_leaf=2)\n",
    "    model_tree.fit(X_train, Y_train)\n",
    "    \n",
    "    mse=mean_squared_error(Y_test, model_tree.predict(X_test))\n",
    "    mses.append(mse)\n",
    "    mae=mean_absolute_error(Y_test, model_tree.predict(X_test))\n",
    "    maes.append(mae)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Average MSE: \" + str(np.mean(mses)))\n",
    "print(\"Average MAE: \" + str(np.mean(maes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.02476966150620715\n",
      "Mean Absolute Error: 0.1330597672645201\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# divide the dataset into 80/20 (training/test)\n",
    "threshold=int(0.8*X.shape[0])\n",
    "\n",
    "X_train = np.array(X[:threshold])\n",
    "Y_train = np.array(y[:threshold])\n",
    "X_test = np.array(X[threshold:])\n",
    "Y_test = np.array(y[threshold:])\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model_tree.predict(X_test)\n",
    "\n",
    "# model evaluation using Root Mean Squared Error and Mean Absolute Error\n",
    "print(\"Mean Squared Error: \" + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 0.016181991548173322\n",
      "Average MAE: 0.10362028774197374\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "#define lists to store te results for each fold\n",
    "maes=[]\n",
    "mses=[]\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train = np.array(X.iloc[train_index])\n",
    "    X_test = np.array(X.iloc[test_index])\n",
    "    Y_train = np.array(y[train_index])\n",
    "    Y_test = np.array(y[test_index])\n",
    "        \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    mse=mean_squared_error(Y_test, model_tree.predict(X_test))\n",
    "    mses.append(mse)\n",
    "    mae=mean_absolute_error(Y_test, model_tree.predict(X_test))\n",
    "    maes.append(mae)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Average MSE: \" + str(np.mean(mses)))\n",
    "print(\"Average MAE: \" + str(np.mean(maes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout with Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.023621476207673436\n",
      "Mean Absolute Error: 0.1312919287807662\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(max_depth=50, min_samples_leaf=2)\n",
    "\n",
    "# divide the dataset into 80/20 (training/test)\n",
    "threshold=int(0.8*X.shape[0])\n",
    "\n",
    "X_train = np.array(X[:threshold])\n",
    "Y_train = np.array(y[:threshold])\n",
    "X_test = np.array(X[threshold:])\n",
    "Y_test = np.array(y[threshold:])\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# model evaluation using Root Mean Squared Error and Mean Absolute Error\n",
    "print(\"Mean Squared Error: \" + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation with Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 0.016181991548173322\n",
      "Average MAE: 0.10362028774197374\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "maes=[]\n",
    "mses=[]\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train = np.array(X.iloc[train_index])\n",
    "    X_test = np.array(X.iloc[test_index])\n",
    "    Y_train = np.array(y[train_index])\n",
    "    Y_test = np.array(y[test_index])\n",
    "        \n",
    "    model = RandomForestRegressor(max_depth=50, min_samples_leaf=2)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    mse=mean_squared_error(Y_test, model_tree.predict(X_test))\n",
    "    mses.append(mse)\n",
    "    mae=mean_absolute_error(Y_test, model_tree.predict(X_test))\n",
    "    maes.append(mae)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"Average MSE: \" + str(np.mean(mses)))\n",
    "print(\"Average MAE: \" + str(np.mean(maes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
